{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10bd922f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from feat import Detector\n",
    "from feat.utils.io import get_test_data_path\n",
    "from feat.plotting import imshow\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pygetwindow as gw\n",
    "from pynput import keyboard\n",
    "#import pyautogui\n",
    "#import keyboard\n",
    "\n",
    "import cv2\n",
    "import mss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188da6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_data_window(Werte):\n",
    "    plt.close()\n",
    "    Index = ['anger','disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral']\n",
    "    fig, ax = plt.subplots(num = 'Emotion Analysis')\n",
    "    ax.bar(Index, Werte)\n",
    "    ax.set_xlabel('Emotion')\n",
    "    ax.set_ylabel('Wert')\n",
    "    ax.set_title('Emotionswerte')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1197790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bring_zoom_meeting_to_front():\n",
    "    \n",
    "    # Den Fenstertitel des Zoom-Meetings angeben\n",
    "    zoom_window_title = \"Zoom Meeting\"\n",
    "    \n",
    "    # Das Zoom-Meeting-Fenster suchen und in den Vordergrund bringen\n",
    "    zoom_window = gw.getWindowsWithTitle(zoom_window_title)[0]\n",
    "    #zoom_window.restore()  # Das Fenster wiederherstellen, falls es minimiert ist\n",
    "    #zoom_window.maximize()  # Das Fenster maximieren\n",
    "    \n",
    "    # Die Position und Größe des Zoom-Meeting-Fensters abrufen\n",
    "    left, top, right, bottom = zoom_window.left, zoom_window.top, zoom_window.right, zoom_window.bottom\n",
    "    \n",
    "    #return left, top, right, bottom, \n",
    "    return zoom_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd2ffeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def take_screenshot(zoom_window, anz_screenshots):\n",
    "    \n",
    "    # Aktuellen Zeitstempel für den Dateinamen generieren\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    screenshot_list = []\n",
    "    screenshot_name_list = []\n",
    "    count = True\n",
    "    \n",
    "    monitor = {\"top\": zoom_window.top, \"left\": zoom_window.left, \"width\": (zoom_window.right-zoom_window.left), \"height\": (zoom_window.bottom - zoom_window.top)}\n",
    "   \n",
    "    with mss.mss() as sct:\n",
    "        while True:\n",
    "            \n",
    "            # Screenshot des ausgewählten Bereichs aufnehmen\n",
    "            #screenshot = pyautogui.screenshot(region=region)\n",
    "            img = np.array(sct.grab(monitor))\n",
    "            screenshot_list.append(img)\n",
    "\n",
    "            screenshot_name = f\"screenshot_{timestamp}\"\n",
    "            screenshot_name_list.append(f\"screenshot_{timestamp}\")\n",
    "\n",
    "            # Speichern des Screenshots\n",
    "            # Dateipfad und Name für den Screenshot\n",
    "            #screenshot_path = f\"./data/screenshot_{timestamp}.png\"\n",
    "            #screenshot.save(f\"./data/{screenshot_name}.png\")\n",
    "            #print (count)\n",
    "                   \n",
    "            if count == anz_screenshots:\n",
    "                break\n",
    "            count += 1\n",
    "        \n",
    "        \n",
    "    #print(f\"Screenshot saved: screenshot_{timestamp}.png\")\n",
    "    return screenshot_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e743a4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pyFeat(screenshot_list,anz_screenshots):\n",
    "    detector = Detector( \n",
    "\tface_model = \"retinaface\",\n",
    "\tlandmark_model = \"mobilefacenet\",\n",
    "\tau_model = 'xgb',\n",
    "\temotion_model = \"resmasknet\",\n",
    "    Facepose_model = \"img2pose\",)\n",
    "    \n",
    "    vorhersage_list = []\n",
    "    emotion_sum =[]\n",
    "    \n",
    "    for i in screenshot_list:\n",
    "        frame=i\n",
    "        detected_faces = detector.detect_faces(frame)\n",
    "        detected_landmarks = detector.detect_landmarks(frame, detected_faces)\n",
    "        vorhersage = detector.detect_emotions(frame, detected_faces, detected_landmarks)\n",
    "        vorhersage_list.append(vorhersage)\n",
    "\n",
    "    #print(vorhersage_list)\n",
    "\n",
    "    for au in vorhersage_list:\n",
    "        for inn in au:\n",
    "            emotion_sum.append(np.sum(inn, axis = 0))\n",
    "            #print(inn)\n",
    "            \n",
    "    emotion = np.mean(emotion_sum, axis = 0)\n",
    "    \n",
    "    #Skalierung der Werte auf 1\n",
    "    emotion_sk = np.divide(emotion, np.sum(emotion))\n",
    "    \n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    #print(emotion_sum)\n",
    "    #print(emotion_sk)\n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    \n",
    "    return emotion_sk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2baae7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualisieren(Werte):\n",
    "    \n",
    "    print(f'die Summe ist {np.sum(Werte)}')\n",
    "    show_data_window(Werte)\n",
    "    #print(Werte)\n",
    "    \n",
    "    #create_gui(mean)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6127ce9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def on_release(key):\n",
    "    \n",
    "    global running\n",
    "    \n",
    "    if key == keyboard.Key.esc:\n",
    "        running = False;\n",
    "        plt.close() \n",
    "        \n",
    "    elif key == keyboard.Key.tab:\n",
    "        #print(\"Next emotion analysis\")\n",
    "        plt.close()\n",
    "        #exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4079c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():        \n",
    "    \n",
    "    #Anzahl an Screenshots die Aufgenommen werden sollen\n",
    "    anz_screenshots = 10\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    while running:\n",
    "\n",
    "        # Screenshot aufnehmen und speichern\n",
    "        screenshot_list = []\n",
    "        region = bring_zoom_meeting_to_front()\n",
    "        #print(region)\n",
    "        screenshot_list = take_screenshot(region, anz_screenshots)\n",
    "        #print (screenshot_list)\n",
    "        emotion = pyFeat(screenshot_list,anz_screenshots)\n",
    "        visualisieren(emotion)\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "        print(timestamp)\n",
    "            \n",
    "    listener.stop()\n",
    "    print(\"stopped!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d96a85-3f81-408c-b2d0-6063d91c97a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferdi\\anaconda3\\envs\\IoT\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "die Summe ist 1.0\n",
      "20230709-094751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferdi\\anaconda3\\envs\\IoT\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Starte das Hauptprogramm\n",
    "\n",
    "running = True\n",
    "listener = keyboard.Listener(on_release=on_release)\n",
    " # run listener in background so that the while loop gets executed\n",
    "listener.start()\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e30c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfae24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabc43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf141df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd4adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380b310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fbd15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d75c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4531fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37b033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78c0fa-3eda-47ea-8279-22e436056723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

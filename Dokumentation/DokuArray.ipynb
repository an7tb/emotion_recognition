{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7619db-328f-47f8-be4f-263fb6e026bb",
   "metadata": {},
   "source": [
    "# 2. Code Beschreibung CodeArray\n",
    "Durch Drücken der **tab** Taste wird Emotionserkennung der Teilnehmer neu durchgeführt.\n",
    "Durch Drücken der **esc** Taste wird das Programm gestoppt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bfa13-d77d-49ca-b0c0-e0295eb85264",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 Verwendete Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10bd922f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from feat import Detector\n",
    "from feat.utils.io import get_test_data_path\n",
    "from feat.plotting import imshow\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pygetwindow as gw\n",
    "from pynput import keyboard\n",
    "#import pyautogui\n",
    "#import keyboard\n",
    "\n",
    "import cv2\n",
    "import mss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a035014-32ef-4d7d-b43f-1409500653f3",
   "metadata": {},
   "source": [
    "## 2.2 Funktion *show_data_window(werte)*\n",
    "Visualisierung der Ergebnisse mit *matplotlib*.\n",
    "\n",
    "**Beschreibung:** *werte* übergibt die ermittelten Emotionen in einem Array aus Zahlen.\n",
    "\n",
    "**Anmerkung:** Die Visualisierung der Ergebnisse durch plt.show() hat zu verantworten, dass der Code nicht loopt. Erst wenn das Plotfenster geschlossen wird, wird der Main-Loop fortgesetzt und die Emotionen neu ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188da6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_data_window(werte):\n",
    "    \n",
    "    # Werte werden gelabelt\n",
    "    Index = ['anger','disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral']\n",
    "    \n",
    "    # Plotfenster wird geöffnet und benannt\n",
    "    fig, ax = plt.subplots(num = 'Emotion Analysis')\n",
    "    \n",
    "    # Achsenzuordnung\n",
    "    ax.bar(Index, werte)\n",
    "    \n",
    "    # Achsenbeschriftung\n",
    "    ax.set_xlabel('Emotion')\n",
    "    ax.set_ylabel('Wert')\n",
    "    ax.set_title('Emotionswerte')\n",
    "    \n",
    "    # Plot wird erstellt\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "attachments": {
    "7fc2bcec-8935-4bc3-97b5-a021bebf9254.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b7244bb2-a4e3-4763-9b0c-12856819913f",
   "metadata": {},
   "source": [
    "## 2.3 Funktion *bring_zoom_meeting_to_front()*\n",
    "Interaktionen mit Zoom-Fenster.\n",
    "\n",
    "**Beschreibung:** Die Größe des Videokonferenz-Fenster wird erkannt und angepasst. Es besteht die Möglichkeit, das Meeting-Fenster in den Vordergrund zu holen.\n",
    "\n",
    "**Anmerkung:** Der Name des Videokonferenz-Fensters muss evtl. an das jeweilige Videokonferenz-Tool angepasst werden (z. B. Meeting oder Teams...).\n",
    "\n",
    "![doku1.jpg](attachment:7fc2bcec-8935-4bc3-97b5-a021bebf9254.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1197790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bring_zoom_meeting_to_front():\n",
    "    \n",
    "    # Den Fenstertitel des Zoom-Meetings angeben\n",
    "    zoom_window_title = \"Zoom Meeting\"\n",
    "    \n",
    "    # Das Zoom-Meeting-Fenster suchen und in den Vordergrund bringen\n",
    "    zoom_window = gw.getWindowsWithTitle(zoom_window_title)[0]\n",
    "    #zoom_window.restore()  # Das Fenster wiederherstellen, falls es minimiert ist\n",
    "    #zoom_window.maximize()  # Das Fenster maximieren\n",
    "    \n",
    "    # Die Position und Größe des Zoom-Meeting-Fensters abrufen\n",
    "    left, top, right, bottom = zoom_window.left, zoom_window.top, zoom_window.right, zoom_window.bottom\n",
    "    \n",
    "    #Rückgabe Größe des Meeting-Fensters\n",
    "    return zoom_window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfaa659-34e2-45de-9765-356baf2a913d",
   "metadata": {},
   "source": [
    "## 2.4 Funktion *take_screenshot(zoom_window, anz_screenshots*\n",
    "Bildschirmaufnahmen werden erstellt.\n",
    "\n",
    "**Beschreibung:** Anzahl der in *main()* angegebenen Screenshots *anz_screenshots* werden nacheinander aufgenommen und der Liste *screenshot_list* angehängt. Es wird nur der Bereich des Bildschirms aufgenommen, der über *zoom_window* übergeben wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd2ffeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def take_screenshot(zoom_window, anz_screenshots):\n",
    "    \n",
    "    # Aktuellen Zeitstempel für den Dateinamen generieren\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    screenshot_list = []\n",
    "    screenshot_name_list = []\n",
    "    count = True\n",
    "    \n",
    "    monitor = {\"top\": zoom_window.top, \"left\": zoom_window.left, \"width\": (zoom_window.right-zoom_window.left), \"height\": (zoom_window.bottom - zoom_window.top)}\n",
    "   \n",
    "    with mss.mss() as sct:\n",
    "        while True:\n",
    "            \n",
    "            # Screenshot des ausgewählten Bereichs aufnehmen\n",
    "            #screenshot = pyautogui.screenshot(region=region)\n",
    "            img = np.array(sct.grab(monitor))\n",
    "            screenshot_list.append(img)\n",
    "            \n",
    "            # Screenshot wird benannt\n",
    "            screenshot_name = f\"screenshot_{timestamp}\"\n",
    "            screenshot_name_list.append(f\"screenshot_{timestamp}\")\n",
    "\n",
    "            # Speichern des Screenshots\n",
    "            # Dateipfad und Name für den Screenshot\n",
    "            #screenshot_path = f\"./data/screenshot_{timestamp}.png\"\n",
    "            #screenshot.save(f\"./data/{screenshot_name}.png\")\n",
    "            #print (count)\n",
    "                   \n",
    "            if count == anz_screenshots:\n",
    "                break\n",
    "            count += 1\n",
    "            \n",
    "    #print(f\"Screenshot saved: screenshot_{timestamp}.png\")\n",
    "    return screenshot_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcafd8b-a81f-4e3d-9ab4-a6596267c2e0",
   "metadata": {},
   "source": [
    "## 2.5 Funktion *pyFeat(screenshot_list,anz_screenshots)*\n",
    "Die Emotion der Gesichter auf den Screenshots werden mithilfe der Toolbox pyFeat erkannt. <https://py-feat.org/pages/intro.html>\n",
    "\n",
    "**Beschreibung:** Die Emotionen 'anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral' werden in Zahlenwerten zwischen 0 und 1 angegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e743a4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pyFeat(screenshot_list,anz_screenshots):\n",
    "    \n",
    "    # Detektor einrichten\n",
    "    detector = Detector( \n",
    "\tface_model = \"retinaface\",\n",
    "\tlandmark_model = \"mobilefacenet\",\n",
    "\tau_model = 'xgb',\n",
    "\temotion_model = \"resmasknet\",\n",
    "    Facepose_model = \"img2pose\",)\n",
    "    \n",
    "    vorhersage_list = []\n",
    "    emotion_sum =[]\n",
    "    \n",
    "    # Emotionserkennung wird durchgeführt und in Arrays gespeichert\n",
    "    for i in screenshot_list:\n",
    "        frame=i\n",
    "        \n",
    "        #Gesichtserkennung\n",
    "        detected_faces = detector.detect_faces(frame)\n",
    "        \n",
    "        #Landmarks ermitteln\n",
    "        detected_landmarks = detector.detect_landmarks(frame, detected_faces)\n",
    "        \n",
    "        #Emotionen bestimmen\n",
    "        vorhersage = detector.detect_emotions(frame, detected_faces, detected_landmarks)\n",
    "        vorhersage_list.append(vorhersage)\n",
    "\n",
    "    \n",
    "    # Elementweise Addition der Arrays \n",
    "    for au in vorhersage_list:\n",
    "        for inn in au:\n",
    "            # Emotion der einzelnen Bilder wird zusammenaddiert\n",
    "            emotion_sum.append(np.sum(inn, axis = 0))\n",
    "            #print(inn)\n",
    "     \n",
    "    #Mittelwertbildung\n",
    "    emotion = np.mean(emotion_sum, axis = 0)\n",
    "    \n",
    "    #Skalierung der Werte auf 1\n",
    "    emotion_sk = np.divide(emotion, np.sum(emotion))\n",
    "    \n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    #print(emotion_sum)\n",
    "    #print(emotion_sk)\n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    \n",
    "    # Emotionsarray wird zurückgegeben\n",
    "    return emotion_sk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb8a46",
   "metadata": {},
   "source": [
    "## 2.6 Funktion *visualisieren(werte)*\n",
    "Diese Funktion leitet bis jetzt nur zu Funktion *show_data_window()* weiter.\n",
    "\n",
    "**Beschreibung:** Dient der Ausgabe des Ergebnisses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2baae7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualisieren(werte):\n",
    "    \n",
    "    print(f'die Summe ist {np.sum(Werte)}')\n",
    "    show_data_window(werte)\n",
    "    #print(Werte)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68a528-5b86-43d5-a7a0-03f4a83b86d5",
   "metadata": {},
   "source": [
    "## 2.7 Funktion *on_release(key)*\n",
    "\n",
    "**Beschreibung:**\n",
    "Code loopt nicht, da Programm bei Funktion show_data_window() bei visualisierung des Graphen stoppt. Durch drücken der **tab** Taste wird neue Emotionserkennung gestartet. Durch drücken der **esc** Taste wird das Programm gestoppt.\n",
    "\n",
    "*on_release()* läuft durchgehend im Hintergrund. Wird eine Taste gedrückt so wird bei Loslassen der Taste überprüft, welche betätigt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6127ce9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def on_release(key):\n",
    "    \n",
    "    # Funktion läuft durchgehend im Hintergrund.\n",
    "    #Globsle Variable running\n",
    "    global running\n",
    "    \n",
    "    # Programm wird durch esc Taste gestoppt.\n",
    "    if key == keyboard.Key.esc:\n",
    "        running = False;\n",
    "        plt.close() \n",
    "        \n",
    "    # Programm wird durch tab Taste fortgesezt, dadurch startet eine neue Emotionserkennung  \n",
    "    elif key == keyboard.Key.tab:\n",
    "        \n",
    "        #Schließen des Fensters\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64582786-dd83-44ce-ab1d-26191acde2a8",
   "metadata": {},
   "source": [
    "## 2.8 Funktion *main()*\n",
    "\n",
    "Hauptprogramm.\n",
    "\n",
    "**Beschreibung** Solange *running=True* werden folgende Funktionen im Loop ausgeführt:\n",
    "\n",
    "-*region = bring_zoom_meeting_to_front()*: Ermittelt Position und Größe des Zoom_Fenster und bringt es in den Vordergrund.\n",
    "\n",
    "-*screenshot_list = take_screenshot(region, anz_screenshots)*: Aufnahme von Screenshots des Zoom-Fensters.\n",
    "\n",
    "-*emotion = pyFeat(screenshot_list,anz_screenshots)*: Detektion der Emotionen auf den Schreenshots.\n",
    "\n",
    "-*visualisieren(emotion)*: Visualisierung der detektierten Emotionen mittels eines Diagramms.\n",
    "\n",
    "Sobald *running=False* wird der Loop unterbrochen und der Keyboard-Listener mit *Listeneer.stop()* gestoppt.\n",
    "\n",
    "**Anmerkung:** Über *anz_screenshots* wird die Anzahl der aufzunemenden Schreenshots festgelegt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4079c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():        \n",
    "    \n",
    "    #Anzahl an Screenshots die Aufgenommen werden sollen\n",
    "    anz_screenshots = 10\n",
    "    # Debugging Purpose dauer eines Programmdurchlaufs bestimmen.\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    while running:\n",
    "\n",
    "        \n",
    "        screenshot_list = []\n",
    "        # Zoom-Fenster wird erkannt\n",
    "        region = bring_zoom_meeting_to_front()\n",
    "        # Screenshot wird erstellt\n",
    "        screenshot_list = take_screenshot(region, anz_screenshots)\n",
    "        # Emotion wird erkannt\n",
    "        emotion = pyFeat(screenshot_list,anz_screenshots)\n",
    "        # Emotion wird Visualisiert\n",
    "        visualisieren(emotion)\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "        print(timestamp)\n",
    "            \n",
    "    listener.stop()\n",
    "    print(\"stopped!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b39937",
   "metadata": {},
   "source": [
    "## 2.9 Startet das Hauptprogramm\n",
    "\n",
    "**Beschreibung:**\n",
    "Initialisiert und startet *keyboard_Listener*.Dieser erkennt Tastatureingabe bei Loslassen der Taste.\n",
    "*main()*-Funktion wird aufgerufen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d96a85-3f81-408c-b2d0-6063d91c97a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferdi\\anaconda3\\envs\\IoT\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "die Summe ist 1.0\n",
      "20230709-094751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferdi\\anaconda3\\envs\\IoT\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Starte das Hauptprogramm\n",
    "\n",
    "#Setze \n",
    "running = True\n",
    "\n",
    "#Initialisiert Keyboard-Listener; Erkennung von Tastatureingabe bei Loslassen der Taste.\n",
    "# run listener in background so that the while loop gets executed\n",
    "listener = keyboard.Listener(on_release=on_release)\n",
    "\n",
    "# Start des Keyboard-Listeners\n",
    "listener.start()\n",
    "\n",
    "#Aufruf des Main-Loops\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
